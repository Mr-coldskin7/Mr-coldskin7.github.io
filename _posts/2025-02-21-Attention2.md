---
title: Attention注意力机制（修正补充版）
date: 2025-02-21 22:00:00 +0800
categories: [Study, LLM]
tags: [study]
---
>其实上篇文章我自己也云里雾里的，所以我花了两天时间看了很多人的视频和讲解，终于搞懂了些，打算重新写一篇

# Attention注意力机制
在正式聊到attention之前，先来讲讲为什么需要attention机制。
## seq2seq模型的弊端
我们知道，seq2seq模型是一种典型的encoder-decoder模型，模型通过Encoder将输入序列编码为固定长度的上下文向量（Context Vector），再由Decoder生成输出序列。这种架构存在两个关键问题但是，seq2seq会遗忘当输入的序列过长的时候，会有两种问题
一是长序列遗忘：当输入序列过长时（如超过30个词），上下文向量难以完整保留所有信息，即便使用LSTM/GRU，长距离依赖仍会衰减。
二是信息对齐缺失：Decoder每一步生成输出时，均使用相同的上下文向量，无法动态关注输入序列中与当前输出最相关的部分。
即使是long short-term memory (LSTM) 这样的RNN结构，它有一条长记忆以及短记忆来进行信息的存储。但是，当输入序列过长时，LSTM仍然会遗忘
我们人类读一些长句子同样也有这方面的问题，所以我们可以像我们人类一样引入注意力机制，人类阅读长文本时，会通过反复回看（Refocus）关键片段辅助理解，而非一次性记忆全部内容。
## Attention的基本思路
attention的思路是学习类似人的注意力机制一样，强调特定的内容是需要得到重视的，那如何体现呢？我是机器我不知道人想要看什么注意什么？
我们人类想要知道或者重视的内容可以通过训练，总结经验知道，那遇到新的怎么办呢？通过相似度来衡量
### 相似度计算
相似度有很多种计算方法，最主要简单的就是进行点乘，再大白话点讲就是高中的余弦计算，如果数值越大则越接近，越小就越背道而驰


![alt text](/assets/2025-02-19-P1.png)


## Attention基本结构
attention主要有三个主要矩阵，分别为：
1. Query：查询矩阵
2. Key：键矩阵
3. Value：值矩阵
初次看起来有点令人费解，为什么要key加上value，只有value不就行了嘛


你可以用经典的苹果来举例，在科技领域里他是一家公司，在果蔬里面是一种水果，符号本身会存在歧义，这也是初始RNN效果不好的原因之一
我们也可以进行类比
### 技术层面：Q/K/V 的分工
attention的灵感一部分来源于搜索引擎，中三个矩阵的核心逻辑是分离「相关性计算」与「信息本身」：
Q（Query）与 K（Key）：共同决定权重分配（哪些信息重要）
像搜索引擎中「搜索词（Q）」与「网页标题（K）」的匹配度计算
V（Value）则为存储实际被提取的语义内容
匹配到网页后，最终展示的「网页正文内容（V）」
那为何不只用 V？
若仅用 V 计算权重，相当于强制用「正文内容」同时承担「相关性匹配」和「信息存储」两个角色。这会限制模型的表达能力——Q/K 允许模型通过不同视角（投影矩阵）动态决定什么信息重要，而 V 则专注于保留原始语义的丰富性。

### 符号学的层面
如果从哲学层面上来讲，跟拉康符号学有关
>能指（Signifier）：符号的物质形式（如语音、文字）
>所指（Signified）：符号引发的心理概念
>意义（Meaning）：通过能指链的差异关系动态生成

更精确的类比则是Q/K 构成能指网络，它们如同符号系统中的能指，本身没有固定意义，但通过彼此的差异关系（点积相似度）生成注意力权重——这对应拉康所说的「能指通过差异产生意义」。

V 是所指的沉淀层，Value 矩阵承载被社会/模型「规训」过的符号意义（如训练数据中的语义关联），但它的显现方式受 Q/K 动态调节——如同所指并非固定，而是被能指网络临时锚定。

注意力权重是「缝合点」
权重分配如同拉康的「缝合点」（point de capiton），将浮动的能指（Q/K）暂时固定到具体的所指（V）上，生成临时的意义结构。

机器与人类符号系统有着的深层共性：意义并非存在于孤立的符号中，而是通过关系网络动态构建的。人类语言中，"树"的意义由它与"森林"、"年轮"、"氧气"等符号的差异关系决定。模型中，一个单词的语义由它与上下文词的注意力交互决定。这种设计让模型摆脱了静态的词嵌入表示，实现了类似人类语言的语境敏感性（context-sensitive meaning）。

Q/K/V 的分工本质上是一种意义生成装置：通过能指（Q/K）的差异游戏，动态地激活所指（V）的特定维度。
### 注意力机制的计算


![alt text](/assets/2025-02-21-P1.png)


回归公式，Q,K,V矩阵都是由输入进过embedding层映射到高维之后乘以训练后的参数矩阵得到
QK^T矩阵是相似度的计算，这里的计算是算内积（或者叫点乘）
为什么要除以根号d？d是k的维度，论文中提到如果直接计算点乘会导致整个数值特别大，会使得梯度消失
前半个是相似度的计算，后半部分乘以V是代表的实际的内容，softmax是进行归一化，将向量里面的值全都化成加起来为1，更加类似于概率
做计算的时候首先要清楚自己查询的对象是谁，对比相似度的对象是谁，搞清楚这些计算是较为简单的。


![alt text](/assets/2025-02-19-P4.png)


在 Transformer 中，注意力输出的结果是对输入序列的重新编码。每个位置的输出都融合了全局上下文信息，而不仅仅是局部信息。
例如，在句子 "I saw a bird in the sky" 中，单词 "bird" 的注意力输出会包含 "sky" 的信息，从而更好地理解 "bird" 的语义。
虽然注意力公式看起来简单，但它通过动态权重分配、信息压缩与聚焦、非线性表达等机制，实现了强大的语义建模能力。它的输出不仅是输入内容的加权和，更是对输入信息的重新编码和高层次抽象，为模型提供了理解语言、处理任务的关键工具。